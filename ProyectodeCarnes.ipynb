{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb27598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffaff844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_02 1\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_03 62\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_04 213\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_05 105\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_06 949\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_07 36\n",
      "C:\\Users\\Carlos\\Documents\\Reconocimiento de imagenes\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 36, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1632\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'train')\n",
    "imgpath = dirname + os.sep \n",
    " \n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    " \n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    " \n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    " \n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca75c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1632\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    " \n",
    "Tipo_Carnes=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    Tipo_Carnes.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    " \n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) \n",
    " \n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaa1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1305, 216, 384, 3) (1305,)\n",
      "Testing data shape :  (327, 216, 384, 3) (327,)\n",
      "Original label: 3\n",
      "After conversion to one-hot: [0. 0. 0. 1. 0. 0. 0.]\n",
      "(1044, 216, 384, 3) (261, 216, 384, 3) (1044, 7) (261, 7)\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    " \n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    " \n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    " \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    " \n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39842789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 216, 384, 35)      980       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 216, 384, 35)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 108, 192, 35)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 108, 192, 35)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 725760)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 35)                25401635  \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 35)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 35)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 252       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25402867 (96.90 MB)\n",
      "Trainable params: 25402867 (96.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "carnes_model = Sequential()\n",
    "carnes_model.add(Conv2D(35, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(216,384,3)))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "carnes_model.add(Dropout(0.5))\n",
    "\n",
    "carnes_model.add(Flatten())\n",
    "carnes_model.add(Dense(35, activation='linear'))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(Dropout(0.5)) \n",
    "carnes_model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "carnes_model.summary()\n",
    "\n",
    "carnes_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 88s 5s/step - loss: 1.9317 - accuracy: 0.5393 - val_loss: 1.8880 - val_accuracy: 0.5939\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 74s 4s/step - loss: 1.7890 - accuracy: 0.5603 - val_loss: 1.6114 - val_accuracy: 0.5939\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - 72s 4s/step - loss: 1.5911 - accuracy: 0.5623 - val_loss: 1.4342 - val_accuracy: 0.5939\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - 72s 4s/step - loss: 1.5260 - accuracy: 0.5642 - val_loss: 1.3956 - val_accuracy: 0.5939\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - 75s 4s/step - loss: 1.4957 - accuracy: 0.5718 - val_loss: 1.3790 - val_accuracy: 0.5939\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - 75s 4s/step - loss: 1.4951 - accuracy: 0.5575 - val_loss: 1.3623 - val_accuracy: 0.5939\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - 77s 5s/step - loss: 1.4986 - accuracy: 0.5651 - val_loss: 1.3610 - val_accuracy: 0.5939\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - 76s 4s/step - loss: 1.5001 - accuracy: 0.5623 - val_loss: 1.3753 - val_accuracy: 0.5939\n",
      "Epoch 9/15\n",
      " 1/17 [>.............................] - ETA: 1:10 - loss: 1.5823 - accuracy: 0.4531"
     ]
    }
   ],
   "source": [
    "\"\"\"\"### Redimensionar todas las imágenes de entrenamiento y validación a (21, 28)\n",
    "train_X_resized = []\n",
    "for image in train_X:\n",
    "    resized_image = cv2.resize(image, (28, 21))\n",
    "    train_X_resized.append(resized_image)\n",
    "\n",
    "train_X_resized = np.array(train_X_resized)\n",
    "\n",
    "valid_X_resized = []\n",
    "for image in valid_X:\n",
    "    resized_image = cv2.resize(image, (28, 21))\n",
    "    valid_X_resized.append(resized_image)\n",
    "\n",
    "valid_X_resized = np.array(valid_X_resized)  \"\"\"\n",
    "\n",
    "carnes_train_dropout = carnes_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    " \n",
    "carnes_model.save(\"carnes_mnist.h5py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8794f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"print(\"Dimensiones de test_X:\", test_X.shape)\n",
    "print(\"Dimensiones de test_Y_one_hot:\", test_Y_one_hot.shape)\n",
    "\n",
    "batch_size = 32  # Puedes ajustar este valor según tu necesidad\n",
    "height = 216\n",
    "width = 384\n",
    "channels = 3  # Esto puede variar según tu modelo\n",
    "\n",
    "# Redimensiona test_X para que coincida con las dimensiones de entrada\n",
    "test_X_reshaped = np.reshape(test_X, (test_X.shape[0], height, width, channels))\n",
    "\n",
    "# Verifica las dimensiones después de la redimensión\n",
    "print(\"Dimensiones de test_X redimensionado:\", test_X_reshaped.shape)\"\"\"\n",
    "test_eval = carnes_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    " \n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5d79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58267e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
